{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# 5 Useful Data Wrangling Techniques Using Python Pandas and data.world   \n## Intro\n### This notebook demonstrates a collection of data wrangling problems I frequently encounter, and my approaches to solving them.    \nWhat this tutorial **is not**: \n* a comprehensive tutorial on data wrangling\n* the only or even the best solutions    \n\nWhat this tutorial **is**:\n* fun and interesting (hopefully)\n* things I encounter often in my work\n* the best solutions I'm aware of (at this time)\n\n### Agenda\n1. Standardize a large, messy datetime column\n2. Change time zones\n3. \"Standardizing\" text (string) columns \n4. Multiprocessing\n5. Reshaping dataframes with melt, pivot, & groupby   \n\n### Dependencies     \n* We'll be using the following Python packages: pandas, numpy, matplotlib, fuzzywuzzy, time, pytz, re, and multiprocessing.     \n* The data is called using the datadotword Python package.    \n  * Instructions for installing and configuring for the first time: https://github.com/datadotworld/data.world-py and https://data.world/nrippner/explore-the-data-world-python-sdk.            \n  * If you installed datadotworld in the past, please ensure that you're using the latest version. In a terminal/command line enter:    \n  `pip install --upgrade datadotworld`"}, {"metadata": {}, "cell_type": "markdown", "source": "### Import Packages"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import pandas as pd               # data wrangling library\nimport datadotworld as ddw        # data.world SDK\nimport numpy as np                # data manipulation, math, linear algebra library\nimport matplotlib.pyplot as plt   # matlab style data visualization library\nfrom fuzzywuzzy import process    # fuzzy string matching\nimport time                       # to measure processing time\nimport pytz                       # time zones\nimport re                         # Python regex\nimport multiprocessing as mp      # multicore distributed processing\nfrom __future__ import print_function\n\n%matplotlib inline", "execution_count": 1, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "pd.set_option('display.max_rows', 40)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n#pd.set_option('max_colwidth', 70)", "execution_count": 2, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Data Wrangling Techniques\n\n## 1. Standardize a large, messy datetime column      \nNote, hat tip to data.world user @hipplec for suggesting this technique on a [thread in data.world](https://data.world/databrett/white-house-visitors-2015-6/discuss/data-preparation/7533)     \nFor this example, we'll use some data I've hosted [here](https://data.world/nrippner/my-dataset) on data.world. The data table we're interested is a selection of three columns from the White House Visitor Logs dataset covering the years 2008 through 2016.     \n![wrang_tut_1.png](https://data.world/api/nrippner/dataset/images/file/raw/wrang_tut_1.png)\n\nWe can see that the data file -- dates.csv -- has 3 columns and nearly 6 million rows.   \nFirst, let's import the data from data.world. I'll demonstrate two methods to efficiently import large datasets from data.world.\n\n#### 1. Copy and past URL     \nDue to the large size (6 million rows), we may want to use the \"Copy URL, Python/Pandas, or R code\" approach to importing this data into Python (as opposed to writing a query) to avoid the compute time associated with querying over so many cells. "}, {"metadata": {}, "cell_type": "markdown", "source": "![wrang_tut_2.png](https://data.world/api/nrippner/dataset/images/file/raw/wrang_tut_2.png)"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# paste results:\ndates_dataframe = pd.read_csv('https://query.data.world/s/hmbt8lm4cw6yj9vshigs178m')", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### 2. Use the `load_dataset` function in datadotworld python package      \nThis approach is highly optimized and convenient -- even with larger data files. Datasets are cached in a directory on your hard drive. "}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "dates = ddw.load_dataset('nrippner/my-dataset')\ndates_dataframe = dates.dataframes['dates']", "execution_count": 4, "outputs": [{"output_type": "stream", "text": "/Users/noahrippner/anaconda/envs/anaconda-py3/lib/python3.6/site-packages/datadotworld/datadotworld.py:194: UserWarning: You are using an outdated copy of nrippner/my-dataset. If you wish to use the latest version, call this function with the argument auto_update=True or force_update=True\n  'force_update=True'.format(dataset_key))\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "print(dates_dataframe.shape)\ndates_dataframe.head(3)", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "(5914766, 3)\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 5, "data": {"text/plain": "  namefirst     namelast appt_start_date\n0    Stella  Adamopoulos          5/1/15\n1    Muriel      Brosman          5/1/15\n2     Avery    Brumfield          5/1/15", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>namefirst</th>\n      <th>namelast</th>\n      <th>appt_start_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Stella</td>\n      <td>Adamopoulos</td>\n      <td>5/1/15</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Muriel</td>\n      <td>Brosman</td>\n      <td>5/1/15</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Avery</td>\n      <td>Brumfield</td>\n      <td>5/1/15</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Our objective now is to convert the `appt_start_date column` to a Series of Pandas datetime objects. The column's dtype is currently numpy `object_` and the individual values are strings."}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "print(dates_dataframe.appt_start_date.dtype)\nprint(dates_dataframe.appt_start_date[0], type(dates_dataframe.appt_start_date[0]))", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "object\n5/1/15 <class 'str'>\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "This seems like it should be relatively simple -- we could just pass the `df.APPT_START_DATE` to the `pandas.to_datetime()` function. Let's try it on a slice made up of the first five percent of the data."}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "start = time.time()\ntest = pd.to_datetime(dates_dataframe.appt_start_date[:295738])\nend = time.time()\nprint(\"%.2f seconds to complete 1/20 of the rows\" % (end-start))", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "28.65 seconds to complete 1/20 of the rows\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "print(\"~ %.1f minutes to complete all 5.9 million rows\" % (((end-start) * 20) / 60.0))", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "~ 9.5 minutes to complete all 5.9 million rows\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Processing 1/20 of the data on my machine took 44 seconds. At that rate, all the rows will take 15 minutes. Let's see if we can speed it up.     "}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "print(\"Number of rows:\", dates_dataframe.shape[0])\nprint(\"Number of unique dates:\", len(dates_dataframe.appt_start_date.unique()))\n\nstart = time.time() \n\ndef lookup(series):\n    dates = {date:pd.to_datetime(date, errors='coerce') for date in series.unique()} \n    return series.map(dates)\n\ndates_dataframe['NewDate'] = lookup(dates_dataframe.appt_start_date)\n\nend = time.time()\n\nprint(\"%.1f seconds\" % (end-start))\nprint(\"Couldn't be parsed:\", sum(dates_dataframe.NewDate.isnull()) - sum(dates_dataframe.appt_start_date.isnull()) )   ", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "Number of rows: 5914766\nNumber of unique dates: 158150\n28.4 seconds\nCouldn't be parsed: 162\n", "name": "stdout"}]}, {"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "In this example :\n* we define a function called `lookup` which is intended to take as its argument a Pandas Series\n* using `dictionary comprehension`, we iterate over each item in the set of unique values in our original series and map each to a `Pandas datetime` object created using the `to_datetime` function\n* the `errors='coerce'` parameter tells the `to_datetime` function to return `np.nan` for values for which a datetime format cannot be inferred\n* using the `pandas.Series.map` method, we return a new Series based on the key:value mappings in our dictionary comprehension.\n* using this approach, we finished in 38 seconds -- a 96% reduction in processing time!     "}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "dates_dataframe.head(3)", "execution_count": 10, "outputs": [{"output_type": "execute_result", "execution_count": 10, "data": {"text/plain": "  namefirst     namelast appt_start_date    NewDate\n0    Stella  Adamopoulos          5/1/15 2015-05-01\n1    Muriel      Brosman          5/1/15 2015-05-01\n2     Avery    Brumfield          5/1/15 2015-05-01", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>namefirst</th>\n      <th>namelast</th>\n      <th>appt_start_date</th>\n      <th>NewDate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Stella</td>\n      <td>Adamopoulos</td>\n      <td>5/1/15</td>\n      <td>2015-05-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Muriel</td>\n      <td>Brosman</td>\n      <td>5/1/15</td>\n      <td>2015-05-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Avery</td>\n      <td>Brumfield</td>\n      <td>5/1/15</td>\n      <td>2015-05-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "dates_dataframe.info()", "execution_count": 11, "outputs": [{"output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5914766 entries, 0 to 5914765\nData columns (total 4 columns):\nnamefirst          object\nnamelast           object\nappt_start_date    object\nNewDate            datetime64[ns]\ndtypes: datetime64[ns](1), object(3)\nmemory usage: 180.5+ MB\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "**Before moving on**, let's think about what caused Pandas `to_datetime` to take so long (17 minutes). Pandas `to_datetime` is processor intensive because it attempts to infer timestamp format, but it can be drastically sped up by including an additional argument: \"_`format=`_\".     \n\n`new_series = pd.to_datetime(old_series, format=\"%Y/%m/%d\")`     \n \nBy specifying the format via the `format=` parameter, the `to_datetime` algorithm skips the step of trying to infer the format, resulting in much shorter processing time. However, as we'll see, we could not use the format argument with this data.    \n\nLet's take a closer look at the datetime column."}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# helpful technique to look at composition of a column\n\n# use apply method to change each value to type string\ndates_dataframe['appt_start_date'] = dates_dataframe.appt_start_date.astype(str)\n\n# dictionary comprehension to create list of the length of each datetime string\nlengths = [len(j) for _, j in enumerate(dates_dataframe.appt_start_date.values)]\n\n# convert to pandas Series in order to use the value_counts method\nlengths = pd.Series(lengths).value_counts()\n\nlengths", "execution_count": 12, "outputs": [{"output_type": "execute_result", "execution_count": 12, "data": {"text/plain": "13    2058611\n12    1351583\n14    1339330\n15     754861\n11     258637\n16     112105\n8       13309\n7        9488\n10       8393\n9        4049\n6        1848\n19       1639\n20        581\n18        325\n3           4\n17          2\n5           1\ndtype: int64"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# function to return a sample datetime string for a given length\ndef inspect_date(length):\n    return dates_dataframe[dates_dataframe.appt_start_date.str.len() == length]\\\n                                                     .appt_start_date.values[0]\n\n# string formatting to format print output\nprint(\"{:<20} {:^12} {:^15}\".format(\"Sample\", \"Length\", \"Count\"))\nprint(\"-\" * 53)\n\nfor i, j in zip(lengths.index, lengths.values):\n    result = inspect_date(i)\n    print(\"{:<20} {:>10} {:<2} {:>10} {:>7}\".format(result, \"length:\", \n                                                    len(result), \"count:\", j))", "execution_count": 13, "outputs": [{"output_type": "stream", "text": "Sample                  Length         Count     \n-----------------------------------------------------\n2/24/10 10:30           length: 13     count: 2058611\n3/5/10 10:15            length: 12     count: 1351583\n12/13/09 16:00          length: 14     count: 1339330\n8/22/2010 12:30         length: 15     count:  754861\n5/1/15 7:00             length: 11     count:  258637\n12/12/2011 18:30        length: 16     count:  112105\n10/22/10                length: 8      count:   13309\n9/23/10                 length: 7      count:    9488\n12/12/2011              length: 10     count:    8393\n1/27/2011               length: 9      count:    4049\n5/1/15                  length: 6      count:    1848\n5/19/2009 7:00:00AM     length: 19     count:    1639\n2/24/2009 11:30:00AM    length: 20     count:     581\n9/24/20096:00:00PM      length: 18     count:     325\nnan                     length: 3      count:       4\n3/6/20099:30:00AM       length: 17     count:       2\n41948                   length: 5      count:       1\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "**The take-away here** is that the datetime column lacks a consistent format. Some entries contain `hour:minute:seconds` and some don't. Sometimes the year is represented with 4 digits, sometimes only 2.    \n\nWhen we specify a format using `\"format=\"` in the function call, `to_datetime` throws an exception when encountering an unexpected type of datetime format. \n\nAs far as I can tell our best bet (because of the lack of a consistent format) was the technique we used above, in which we used `to_datetime` on the set of unique values, and transformed the Series with the `map` method."}, {"metadata": {}, "cell_type": "markdown", "source": "## 2. Changing time zones     \nThis is pretty straightforward, but worth looking at.    \n\nFirst, let's download and import some timestamp data that has hour:minute:second.    \n\nWe'll use the `datadotworld.query` method to write a SQL query."}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "time_df = ddw.query('nrippner/datetime-sample',\n                    'SELECT * FROM time_data LIMIT 1000').dataframe\n\ntime_df['created_date'] = pd.to_datetime(time_df.created_date)", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "* The `created_date` column (after feeding it to the `to_datetime` function) is a datetime64 object.  \n* The individual objects that the `created_date` column comprises are pandas Timestamps."}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "time_df.info()", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 2 columns):\nid              1000 non-null int64\ncreated_date    1000 non-null datetime64[ns]\ndtypes: datetime64[ns](1), int64(1)\nmemory usage: 15.7 KB\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "item = time_df.created_date[0]\nprint(item)\nprint(type(item))", "execution_count": 16, "outputs": [{"output_type": "stream", "text": "2017-02-18 08:05:01\n<class 'pandas._libs.tslib.Timestamp'>\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Let's imagine that we want to convert the data to Central time. By default, pandas Timestamp objects are _time zone agnostic_. Therefore, we have to ascertain the baseline timezone, because the data alone will not tell us. In this case, let's assume that I either contacted the database administrator or the database's documentation and learned that the time stamps were measured in UTC format (a common standard for databases).   \n     \nKnowing we're starting from UTC, here's how to go about changing the time zone in pandas. We'll use the `pytz` to get a list of time zones."}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "all_tz = pytz.all_timezones\n#all_tz", "execution_count": 17, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "time_df['central_tz'] = \\\n         time_df.created_date.apply(lambda x: x.tz_localize('UTC').tz_convert('US/Central'))", "execution_count": 18, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "print(\"time zone:\", time_df.central_tz[0].tz)\ntime_df.head()", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "time zone: US/Central\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 19, "data": {"text/plain": "        id        created_date                central_tz\n0  1164116 2017-02-18 08:05:01 2017-02-18 02:05:01-06:00\n1  1164117 2017-02-18 08:05:05 2017-02-18 02:05:05-06:00\n2  1164118 2017-02-18 08:05:06 2017-02-18 02:05:06-06:00\n3  1164119 2017-02-18 08:05:09 2017-02-18 02:05:09-06:00\n4  1164120 2017-02-18 08:05:10 2017-02-18 02:05:10-06:00", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>created_date</th>\n      <th>central_tz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1164116</td>\n      <td>2017-02-18 08:05:01</td>\n      <td>2017-02-18 02:05:01-06:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1164117</td>\n      <td>2017-02-18 08:05:05</td>\n      <td>2017-02-18 02:05:05-06:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1164118</td>\n      <td>2017-02-18 08:05:06</td>\n      <td>2017-02-18 02:05:06-06:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1164119</td>\n      <td>2017-02-18 08:05:09</td>\n      <td>2017-02-18 02:05:09-06:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1164120</td>\n      <td>2017-02-18 08:05:10</td>\n      <td>2017-02-18 02:05:10-06:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## 3. \"Standardizing\" text (string) columns      \nIn this section, we'll see how to correct discrepancies between two columns.     \n\n> The typical use case is when you want to join two separate datasets, each with a common column to join on (for example, city name). More often than not we find spelling, syntax, or formatting differences between columns, which need to be brought into symmetry prior to executing a join.    \n\nIn this example, our goal is to join two datasets on a \"Country\" column. In this case, we're going to join a dataset on refugees by country with one for population by country, with the goal of creating a \"Refugees Per Capita\" feature."}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "refugee_df = ddw.query('nrippner/refugee-host-nations',\n   ''' SELECT `unhcr_2015.csv/unhcr_2015`.`Refugees (incl. refugee-like situations)` as Refugees,\n              `unhcr_2015.csv/unhcr_2015`.`Country / territory of asylum/residence` as Country\n       FROM `unhcr_2015.csv/unhcr_2015` ''').dataframe\n\n# filter out instances where Refugees = '*'\nrefugee_df = refugee_df[refugee_df.Refugees != '*']\n\n# use pandas.to_numeric function to convert column to np.float64 dtype\nrefugee_df['Refugees'] = pd.to_numeric(refugee_df.Refugees)\n\n# use pandas.DataFrame.groupby to get sum of refugees per country\nrefugee_df = refugee_df.groupby('Country', as_index=False).sum()", "execution_count": 20, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "population_df = ddw.query('nrippner/refugee-host-nations',\n    '''SELECT `worldbank_indicators.csv/worldbank_indicators`.`2015 [YR2015]` as Population_2015,\n               `worldbank_indicators.csv/worldbank_indicators`.`Country Name` as Country\n       FROM `worldbank_indicators.csv/worldbank_indicators`\n       WHERE `worldbank_indicators.csv/worldbank_indicators`.`Series Name`\n       LIKE \"Population, total\"''').dataframe\n", "execution_count": 21, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# show # of unique countries in each DataFrame\nprint(\"The refugee dataframe has %d unique Countries\" % len(refugee_df.Country.unique()))\nprint(\"The population dataframe has %d unique Countries\" % len(population_df.Country.unique()))", "execution_count": 22, "outputs": [{"output_type": "stream", "text": "The refugee dataframe has 170 unique Countries\nThe population dataframe has 244 unique Countries\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# In this step we use two Pandas.Series methods (Series.unique() and Series.isin()) to show the intersection between the two\n# columns over the 'Country' column. \n\nA = sum(pd.Series(refugee_df.Country.unique()).isin(population_df.Country))\nB = sum(pd.Series(population_df.Country.unique()).isin(refugee_df.Country))\nprint(\"%d out of %d unique countries in refugee_df are in population_df\" \n                                   % (A, len(refugee_df.Country.unique())))\nprint(\"%d out of %d unique countries in population_df are in refugee_df\" \n                                 % (B, len(population_df.Country.unique())))", "execution_count": 23, "outputs": [{"output_type": "stream", "text": "143 out of 170 unique countries in refugee_df are in population_df\n143 out of 244 unique countries in population_df are in refugee_df\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "The DataFrames share 143 unique countries. An inner merge at this point would result in a DataFrame 143 rows in length. We can probably do better than that.    \nTake a look at the 27 countries in refugee_df that don't match"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# use the .unique() method to give a numpy array of the unique countries.\n# feed it to pd.Series() to convert it to a Pandas Series object so we can use\n# the .isin() method\ncountries_unique = pd.Series(refugee_df.Country.unique())\ncountries_unique[~countries_unique.isin(population_df.Country)]\n# (the ~ symbol before \"countries\" means \"not\")\n# the items from refugee_df.Country that are not in population_df.Country", "execution_count": 24, "outputs": [{"output_type": "execute_result", "execution_count": 24, "data": {"text/plain": "10                                       Bahamas\n17              Bolivia (Plurinational State of)\n30                          Central African Rep.\n34                          China, Hong Kong SAR\n36                                         Congo\n41                                    Czech Rep.\n42                                 C\u00f4te d'Ivoire\n43                   Dem. People's Rep. of Korea\n44                        Dem. Rep. of the Congo\n47                                Dominican Rep.\n49                                         Egypt\n58                                        Gambia\n73                        Iran (Islamic Rep. of)\n84                                    Kyrgyzstan\n100             Micronesia (Federated States of)\n108                                        Nauru\n126                                Rep. of Korea\n127                              Rep. of Moldova\n133        Serbia and Kosovo (S/RES/1244 (1999))\n136                                     Slovakia\n147                             Syrian Arab Rep.\n150    The former Yugoslav Republic of Macedonia\n161                      United Rep. of Tanzania\n162                     United States of America\n165           Venezuela (Bolivarian Republic of)\n166                                     Viet Nam\n167                                        Yemen\ndtype: object"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Now let's reconcile the country names between the two DataFrames wherever possible.  "}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# use list comprehension, the Python \"enumerate\" function, \n# and the pandas Series.isin() method to make list of non-matching countries\nno_match = [[i, refugee_df.Country.unique()[i]] for i, j in \n     enumerate(pd.Series(refugee_df.Country.unique()).isin(population_df.Country)) if not j]", "execution_count": 25, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# a list of lists that pd.DataFrame will accept\nno_match", "execution_count": 26, "outputs": [{"output_type": "execute_result", "execution_count": 26, "data": {"text/plain": "[[10, 'Bahamas'],\n [17, 'Bolivia (Plurinational State of)'],\n [30, 'Central African Rep.'],\n [34, 'China, Hong Kong SAR'],\n [36, 'Congo'],\n [41, 'Czech Rep.'],\n [42, \"C\u00f4te d'Ivoire\"],\n [43, \"Dem. People's Rep. of Korea\"],\n [44, 'Dem. Rep. of the Congo'],\n [47, 'Dominican Rep.'],\n [49, 'Egypt'],\n [58, 'Gambia'],\n [73, 'Iran (Islamic Rep. of)'],\n [84, 'Kyrgyzstan'],\n [100, 'Micronesia (Federated States of)'],\n [108, 'Nauru'],\n [126, 'Rep. of Korea'],\n [127, 'Rep. of Moldova'],\n [133, 'Serbia and Kosovo (S/RES/1244 (1999))'],\n [136, 'Slovakia'],\n [147, 'Syrian Arab Rep.'],\n [150, 'The former Yugoslav Republic of Macedonia'],\n [161, 'United Rep. of Tanzania'],\n [162, 'United States of America'],\n [165, 'Venezuela (Bolivarian Republic of)'],\n [166, 'Viet Nam'],\n [167, 'Yemen']]"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# create dataframe\nno_match = pd.DataFrame(no_match, index=range(len(no_match)), columns=['idx', 'Country'])", "execution_count": 27, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# fuzzy matching, list comprehension, pd.Series.isin and enumerate to help find matches\n# add results as a new column in our dataframe for easy viewing\nno_match['Matches'] = [process.extractBests(j, population_df.Country.unique(), limit=3,\n                        score_cutoff=70) for _, j in enumerate(no_match.Country.values)]", "execution_count": 28, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "pd.options.display.max_colwidth = 80\nno_match", "execution_count": 29, "outputs": [{"output_type": "execute_result", "execution_count": 29, "data": {"text/plain": "    idx                                    Country                                                                       Matches\n0    10                                    Bahamas                                                          [(Bahamas, The, 90)]\n1    17           Bolivia (Plurinational State of)                               [(Bolivia, 90), (Isle of Man, 86), (Tonga, 72)]\n2    30                       Central African Rep.        [(Central African Republic, 88), (Congo, Rep., 86), (Korea, Rep., 86)]\n3    34                       China, Hong Kong SAR             [(Hong Kong SAR, China, 95), (China, 90), (Macao SAR, China, 71)]\n4    36                                      Congo                   [(Congo, Dem. Rep., 90), (Congo, Rep., 90), (Mongolia, 72)]\n5    41                                 Czech Rep.        [(Czech Republic, 90), (Congo, Dem. Rep., 86), (Egypt, Arab Rep., 86)]\n6    42                              C\u00f4te d'Ivoire                                                         [(Cote d'Ivoire, 96)]\n7    43                Dem. People's Rep. of Korea  [(Korea, Dem. People\u2019s Rep., 95), (Congo, Dem. Rep., 86), (Congo, Rep., 86)]\n8    44                     Dem. Rep. of the Congo               [(Congo, Dem. Rep., 95), (Bahamas, The, 86), (Congo, Rep., 86)]\n9    47                             Dominican Rep.   [(Dominica, 90), (Korea, Dem. People\u2019s Rep., 86), (Dominican Republic, 84)]\n10   49                                      Egypt                                                      [(Egypt, Arab Rep., 90)]\n11   58                                     Gambia                              [(Gambia, The, 90), (Zambia, 83), (Namibia, 77)]\n12   73                     Iran (Islamic Rep. of)              [(Iran, Islamic Rep., 95), (Congo, Rep., 86), (Isle of Man, 86)]\n13   84                                 Kyrgyzstan                                                                            []\n14  100           Micronesia (Federated States of)         [(Isle of Man, 86), (Micronesia, Fed. Sts., 86), (United States, 86)]\n15  108                                      Nauru                                                                            []\n16  126                              Rep. of Korea                          [(Korea, Rep., 95), (Korea, Dem. People\u2019s Rep., 86)]\n17  127                            Rep. of Moldova           [(Moldova, 90), (Congo, Rep., 86), (Korea, Dem. People\u2019s Rep., 86)]\n18  133      Serbia and Kosovo (S/RES/1244 (1999))                       [(Kosovo, 90), (Serbia, 90), (Antigua and Barbuda, 86)]\n19  136                                   Slovakia                                       [(Slovenia, 75), (Slovak Republic, 74)]\n20  147                           Syrian Arab Rep.       [(Congo, Rep., 86), (Korea, Dem. People\u2019s Rep., 86), (Korea, Rep., 86)]\n21  150  The former Yugoslav Republic of Macedonia    [(Bahamas, The, 86), (Central African Republic, 86), (Czech Republic, 86)]\n22  161                    United Rep. of Tanzania                   [(Tanzania, 90), (Congo, Dem. Rep., 86), (Congo, Rep., 86)]\n23  162                   United States of America                [(United States, 90), (Isle of Man, 86), (United Kingdom, 86)]\n24  165         Venezuela (Bolivarian Republic of)           [(Czech Republic, 86), (Dominican Republic, 86), (Isle of Man, 86)]\n25  166                                   Viet Nam                                                               [(Vietnam, 93)]\n26  167                                      Yemen                                                           [(Yemen, Rep., 90)]", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>idx</th>\n      <th>Country</th>\n      <th>Matches</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>Bahamas</td>\n      <td>[(Bahamas, The, 90)]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17</td>\n      <td>Bolivia (Plurinational State of)</td>\n      <td>[(Bolivia, 90), (Isle of Man, 86), (Tonga, 72)]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30</td>\n      <td>Central African Rep.</td>\n      <td>[(Central African Republic, 88), (Congo, Rep., 86), (Korea, Rep., 86)]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34</td>\n      <td>China, Hong Kong SAR</td>\n      <td>[(Hong Kong SAR, China, 95), (China, 90), (Macao SAR, China, 71)]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>36</td>\n      <td>Congo</td>\n      <td>[(Congo, Dem. Rep., 90), (Congo, Rep., 90), (Mongolia, 72)]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>41</td>\n      <td>Czech Rep.</td>\n      <td>[(Czech Republic, 90), (Congo, Dem. Rep., 86), (Egypt, Arab Rep., 86)]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>42</td>\n      <td>C\u00f4te d'Ivoire</td>\n      <td>[(Cote d'Ivoire, 96)]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>43</td>\n      <td>Dem. People's Rep. of Korea</td>\n      <td>[(Korea, Dem. People\u2019s Rep., 95), (Congo, Dem. Rep., 86), (Congo, Rep., 86)]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>44</td>\n      <td>Dem. Rep. of the Congo</td>\n      <td>[(Congo, Dem. Rep., 95), (Bahamas, The, 86), (Congo, Rep., 86)]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>47</td>\n      <td>Dominican Rep.</td>\n      <td>[(Dominica, 90), (Korea, Dem. People\u2019s Rep., 86), (Dominican Republic, 84)]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>49</td>\n      <td>Egypt</td>\n      <td>[(Egypt, Arab Rep., 90)]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>58</td>\n      <td>Gambia</td>\n      <td>[(Gambia, The, 90), (Zambia, 83), (Namibia, 77)]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>73</td>\n      <td>Iran (Islamic Rep. of)</td>\n      <td>[(Iran, Islamic Rep., 95), (Congo, Rep., 86), (Isle of Man, 86)]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>84</td>\n      <td>Kyrgyzstan</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>100</td>\n      <td>Micronesia (Federated States of)</td>\n      <td>[(Isle of Man, 86), (Micronesia, Fed. Sts., 86), (United States, 86)]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>108</td>\n      <td>Nauru</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>126</td>\n      <td>Rep. of Korea</td>\n      <td>[(Korea, Rep., 95), (Korea, Dem. People\u2019s Rep., 86)]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>127</td>\n      <td>Rep. of Moldova</td>\n      <td>[(Moldova, 90), (Congo, Rep., 86), (Korea, Dem. People\u2019s Rep., 86)]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>133</td>\n      <td>Serbia and Kosovo (S/RES/1244 (1999))</td>\n      <td>[(Kosovo, 90), (Serbia, 90), (Antigua and Barbuda, 86)]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>136</td>\n      <td>Slovakia</td>\n      <td>[(Slovenia, 75), (Slovak Republic, 74)]</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>147</td>\n      <td>Syrian Arab Rep.</td>\n      <td>[(Congo, Rep., 86), (Korea, Dem. People\u2019s Rep., 86), (Korea, Rep., 86)]</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>150</td>\n      <td>The former Yugoslav Republic of Macedonia</td>\n      <td>[(Bahamas, The, 86), (Central African Republic, 86), (Czech Republic, 86)]</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>161</td>\n      <td>United Rep. of Tanzania</td>\n      <td>[(Tanzania, 90), (Congo, Dem. Rep., 86), (Congo, Rep., 86)]</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>162</td>\n      <td>United States of America</td>\n      <td>[(United States, 90), (Isle of Man, 86), (United Kingdom, 86)]</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>165</td>\n      <td>Venezuela (Bolivarian Republic of)</td>\n      <td>[(Czech Republic, 86), (Dominican Republic, 86), (Isle of Man, 86)]</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>166</td>\n      <td>Viet Nam</td>\n      <td>[(Vietnam, 93)]</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>167</td>\n      <td>Yemen</td>\n      <td>[(Yemen, Rep., 90)]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Most of these worked well, but for some reason Venezuela (line 24) and Kyrgyzstan (line 13) didn't properly yield a match (although they probably should have).    \nWe'll use pd.Series.str.contains() to manually take a look."}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "population_df[population_df.Country.str.contains('Venez')]", "execution_count": 30, "outputs": [{"output_type": "execute_result", "execution_count": 30, "data": {"text/plain": "     Population_2015        Country\n207       31108083.0  Venezuela, RB", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Population_2015</th>\n      <th>Country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>207</th>\n      <td>31108083.0</td>\n      <td>Venezuela, RB</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "* Now, we'll create a nested dictionary to input into the pd.DataFrame.replace function on the refugee_df dataframe.    \n* The dictionary targets one column in the refugee_df dataframe: 'Country'.    \n* The pd.DataFrame.replace function will look within the refugee_df.Country column, find each key in the lower nested dictionary, and replace them with their corresponding values.   \n\nThis process is (when possible), transforming the country names in refugee_df to match correctly with the same country's name in population_df."}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "repl = { 'Country' : {'Czech Rep.':'Czech Republic',\n                      'Dominican Rep.':'Dominican Republic',\n                      'Egypt':'Egypt, Arab Rep.',\n                      'Micronesia (Federated States of)':'Micronesia, Fed. Sts.',\n                      'Gambia':'Gambia, The',\n                      'China, Hong Kong SAR':'Hong Kong SAR, China',\n                      'Iran (Islamic Rep. of)':'Iran, Islamic Rep.',\n                      'Kyrgyzstan':'Kyrgyz Republic',\n                      'Rep. of Korea':'Korea, Rep.',\n                      'Serbia and Kosovo (S/RES/1244 (1999))':'Serbia',\n                      'Slovakia':'Slovak Republic',\n                      'Syrian Arab Rep.':'Syrian Arab Republic',\n                      'United Rep. of Tanzania':'Tanzania',\n                      'United States of America':'United States',\n                      'Venezuela (Bolivarian Republic of)':'Venezuela, RB',\n                      'Viet Nam':'Vietnam',\n                      'Yemen':'Yemen, Rep.',\n                      'Bahamas':'Bahamas, The',\n                      'Bolivia (Plurinational State of)':'Bolivia',\n                      'Central African Rep.':'Central African Republic',\n                      'C\u00c3\u00b4te d\\'Ivoire':'Cote d\\'Ivoire',\n                      'Dem. Rep. of the Congo':'Congo, Dem. Rep.',\n                      'Congo':'Congo, Rep.',\n                      'Rep. of Moldova':'Moldova',\n                      'The former Yugoslav Republic of Macedonia':'Macedonia, FYR',\n                      'Dem. People\\'s Rep. of Korea':'Korea, Dem. People\u00e2\u0080\u0099s Rep.'\n                     }\n       }\n\nrefugee_df.replace(repl, inplace=True)", "execution_count": 31, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "ref_unique = pd.Series(refugee_df.Country.unique())\na = 'count of number of non-matching country names'\nprint(\"{} {:_>10}\".format(a, len(ref_unique[~ref_unique.isin(population_df.Country)])))\nb = 'which country were we unable to match?'\nprint(\"{} {:_>21}\".format(b, ref_unique[~ref_unique.isin(population_df.Country)].values[0]))\n", "execution_count": 32, "outputs": [{"output_type": "stream", "text": "count of number of non-matching country names _________3\nwhich country were we unable to match? ________C\u00f4te d'Ivoire\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "After reconciling the spelling differences, the only country that can't be matched\nis Nauru. \nNow we have a matching column in each dataframe to join on."}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# merge dataframes\nrefugee_df = refugee_df.merge(population_df, on='Country', how='inner')\n\n# create new feature\nrefugee_df['Refugees_Per_Cap'] = refugee_df.Refugees / refugee_df.Population_2015\n\nrefugee_df.head()", "execution_count": 33, "outputs": [{"output_type": "execute_result", "execution_count": 33, "data": {"text/plain": "               Country  Refugees  Population_2015  Refugees_Per_Cap\n0          Afghanistan    257553       32526562.0          0.007918\n1              Albania        79        2889167.0          0.000027\n2              Algeria     94161       39666519.0          0.002374\n3               Angola     15537       25021974.0          0.000621\n4  Antigua and Barbuda        15          91818.0          0.000163", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Refugees</th>\n      <th>Population_2015</th>\n      <th>Refugees_Per_Cap</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Afghanistan</td>\n      <td>257553</td>\n      <td>32526562.0</td>\n      <td>0.007918</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Albania</td>\n      <td>79</td>\n      <td>2889167.0</td>\n      <td>0.000027</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Algeria</td>\n      <td>94161</td>\n      <td>39666519.0</td>\n      <td>0.002374</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Angola</td>\n      <td>15537</td>\n      <td>25021974.0</td>\n      <td>0.000621</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Antigua and Barbuda</td>\n      <td>15</td>\n      <td>91818.0</td>\n      <td>0.000163</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## 4. Multiprocessing      \nHat tip to [this blog](http://www.racketracer.com/2016/07/06/pandas-in-parallel/), where I discovered this technique.      \nSometimes despite our best efforts to write good Python/Pandas code, we have complex computations that we'd like to speed up. For processor-intensive jobs, multiprocessing is a solution.    "}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#import multiprocessor as mp\n\n# first, define the function that you want to distribute across multiple CPU cores\n# Note, this is a poorly written function, so we can play with multiprocessing\ndef func(s_split):\n    \n    def apply_func(x):\n        count = 0\n        for letter in list(x):\n            for country in population_df.Country.values:\n                if letter in list(country):\n                    count += 1\n        return count\n    \n    for n in range(500):\n        out = s_split.apply(apply_func)\n    return out\n\n# multiprocessing\nnum_partitions = 10\nnum_cores = 6\n\ndef parallelize_series(s, func):\n    s_split = np.array_split(s, num_partitions)\n    pool = mp.Pool(num_cores)\n    output = pd.concat(pool.map(func, s_split))\n    pool.close()\n    pool.join()\n    return output\n\nstart = time.time()\nfunc(refugee_df.Country)\nend = time.time()\nprint(\"single job: %.2f\" % (end - start))\n\nstart = time.time()\nref_unique['letter_counts'] = parallelize_series(refugee_df.Country, func)\nend = time.time() \nprint(\"multiprocessor: %.2f\" % (end - start))", "execution_count": 34, "outputs": [{"output_type": "stream", "text": "single job: 90.02\nmultiprocessor: 27.08\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "We see the improvement in processing time.   \nThe screenshot shows the jobs running concurrently on different cores of my quad-core laptop.\n\n![wrang_tut_3.png](https://data.world/api/nrippner/dataset/images/file/raw/wrang_tut_3.png)"}, {"metadata": {}, "cell_type": "markdown", "source": "## 5. Reshaping dataframes with melt & pivot    \n\n**transform from \"wide\" to \"long\" format using melt**    \nFor this exercise, we'll use the [Worldbank WDI Indicators data](https://data.world/worldbank/world-development-indicators) "}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# population estimates by nation, by year\npop_dataframe = ddw.query(dataset_key='worldbank/world-development-indicators',\n                          query = '''SELECT * FROM wdidata\n                                    WHERE indicator_code = 'GC.TAX.TOTL.GD.ZS'\n                                  ''').dataframe", "execution_count": 35, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "print(pop_dataframe.shape)\npop_dataframe.head()", "execution_count": 36, "outputs": [{"output_type": "stream", "text": "(264, 61)\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 36, "data": {"text/plain": "  country_name country_code          indicator_name     indicator_code  1960  1961  1962  1963  1964  1965  1966  1967  1968  1969  1970  1971  1972  1973  1974  1975  1976  1977  1978  1979  1980  1981      1982      1983      1984      1985      1986  1987      1988      1989       1990       1991       1992       1993       1994       1995       1996       1997       1998       1999       2000       2001       2002       2003       2004       2005       2006       2007       2008       2009       2010       2011       2012       2013       2014       2015  2016\n0      Belgium          BEL  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None   NaN   NaN       NaN       NaN       NaN       NaN       NaN   NaN       NaN       NaN        NaN        NaN        NaN        NaN        NaN  25.485975  25.830408  26.347464  26.946863  26.797393  27.079800  26.640067  25.543235  24.949140  25.376233  25.353296  25.169655  24.710933  25.087498  23.620610  24.333897  24.711321  25.710013  26.210614  26.199248  24.634038  None\n1       Belize          BLZ  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None   NaN   NaN       NaN       NaN       NaN       NaN       NaN   NaN       NaN       NaN  21.406125  20.710974  19.935586  19.521906  19.916118  18.752931  19.538847  19.655231  19.698402  17.401511  17.827594  18.702015  19.299785  19.174321  19.663410  21.303913  21.784112  22.922524  21.699112  22.481123  23.596652  22.570675  22.457886  23.315711  23.390476        NaN  None\n2        Benin          BEN  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None   NaN   NaN       NaN       NaN       NaN       NaN       NaN   NaN       NaN       NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN  13.687221  14.412549  14.271349  14.635897  13.809283  14.213124  15.694394  16.115668  14.994099  15.533592  14.823271  14.413500  15.385296        NaN        NaN  None\n3      Bermuda          BMU  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None   NaN   NaN       NaN       NaN       NaN       NaN       NaN   NaN       NaN       NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN  None\n4       Bhutan          BTN  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None  None   NaN   NaN  5.429695  6.278335  7.208049  6.379292  6.753702   NaN  5.970228  5.191277   4.413943   4.952478   5.048773   6.233570   5.924630   6.611706   7.530245   6.538898   8.013738   7.015198  10.017850   8.527340   9.249166   9.365508   7.682697   8.346578   9.030991   7.519467   8.415932   9.235527  13.143297  13.507578  14.704148  14.377883  13.336893        NaN  None", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country_name</th>\n      <th>country_code</th>\n      <th>indicator_name</th>\n      <th>indicator_code</th>\n      <th>1960</th>\n      <th>1961</th>\n      <th>1962</th>\n      <th>1963</th>\n      <th>1964</th>\n      <th>1965</th>\n      <th>1966</th>\n      <th>1967</th>\n      <th>1968</th>\n      <th>1969</th>\n      <th>1970</th>\n      <th>1971</th>\n      <th>1972</th>\n      <th>1973</th>\n      <th>1974</th>\n      <th>1975</th>\n      <th>1976</th>\n      <th>1977</th>\n      <th>1978</th>\n      <th>1979</th>\n      <th>1980</th>\n      <th>1981</th>\n      <th>1982</th>\n      <th>1983</th>\n      <th>1984</th>\n      <th>1985</th>\n      <th>1986</th>\n      <th>1987</th>\n      <th>1988</th>\n      <th>1989</th>\n      <th>1990</th>\n      <th>1991</th>\n      <th>1992</th>\n      <th>1993</th>\n      <th>1994</th>\n      <th>1995</th>\n      <th>1996</th>\n      <th>1997</th>\n      <th>1998</th>\n      <th>1999</th>\n      <th>2000</th>\n      <th>2001</th>\n      <th>2002</th>\n      <th>2003</th>\n      <th>2004</th>\n      <th>2005</th>\n      <th>2006</th>\n      <th>2007</th>\n      <th>2008</th>\n      <th>2009</th>\n      <th>2010</th>\n      <th>2011</th>\n      <th>2012</th>\n      <th>2013</th>\n      <th>2014</th>\n      <th>2015</th>\n      <th>2016</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Belgium</td>\n      <td>BEL</td>\n      <td>Tax revenue (% of GDP)</td>\n      <td>GC.TAX.TOTL.GD.ZS</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>25.485975</td>\n      <td>25.830408</td>\n      <td>26.347464</td>\n      <td>26.946863</td>\n      <td>26.797393</td>\n      <td>27.079800</td>\n      <td>26.640067</td>\n      <td>25.543235</td>\n      <td>24.949140</td>\n      <td>25.376233</td>\n      <td>25.353296</td>\n      <td>25.169655</td>\n      <td>24.710933</td>\n      <td>25.087498</td>\n      <td>23.620610</td>\n      <td>24.333897</td>\n      <td>24.711321</td>\n      <td>25.710013</td>\n      <td>26.210614</td>\n      <td>26.199248</td>\n      <td>24.634038</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Belize</td>\n      <td>BLZ</td>\n      <td>Tax revenue (% of GDP)</td>\n      <td>GC.TAX.TOTL.GD.ZS</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.406125</td>\n      <td>20.710974</td>\n      <td>19.935586</td>\n      <td>19.521906</td>\n      <td>19.916118</td>\n      <td>18.752931</td>\n      <td>19.538847</td>\n      <td>19.655231</td>\n      <td>19.698402</td>\n      <td>17.401511</td>\n      <td>17.827594</td>\n      <td>18.702015</td>\n      <td>19.299785</td>\n      <td>19.174321</td>\n      <td>19.663410</td>\n      <td>21.303913</td>\n      <td>21.784112</td>\n      <td>22.922524</td>\n      <td>21.699112</td>\n      <td>22.481123</td>\n      <td>23.596652</td>\n      <td>22.570675</td>\n      <td>22.457886</td>\n      <td>23.315711</td>\n      <td>23.390476</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Benin</td>\n      <td>BEN</td>\n      <td>Tax revenue (% of GDP)</td>\n      <td>GC.TAX.TOTL.GD.ZS</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13.687221</td>\n      <td>14.412549</td>\n      <td>14.271349</td>\n      <td>14.635897</td>\n      <td>13.809283</td>\n      <td>14.213124</td>\n      <td>15.694394</td>\n      <td>16.115668</td>\n      <td>14.994099</td>\n      <td>15.533592</td>\n      <td>14.823271</td>\n      <td>14.413500</td>\n      <td>15.385296</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bermuda</td>\n      <td>BMU</td>\n      <td>Tax revenue (% of GDP)</td>\n      <td>GC.TAX.TOTL.GD.ZS</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bhutan</td>\n      <td>BTN</td>\n      <td>Tax revenue (% of GDP)</td>\n      <td>GC.TAX.TOTL.GD.ZS</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.429695</td>\n      <td>6.278335</td>\n      <td>7.208049</td>\n      <td>6.379292</td>\n      <td>6.753702</td>\n      <td>NaN</td>\n      <td>5.970228</td>\n      <td>5.191277</td>\n      <td>4.413943</td>\n      <td>4.952478</td>\n      <td>5.048773</td>\n      <td>6.233570</td>\n      <td>5.924630</td>\n      <td>6.611706</td>\n      <td>7.530245</td>\n      <td>6.538898</td>\n      <td>8.013738</td>\n      <td>7.015198</td>\n      <td>10.017850</td>\n      <td>8.527340</td>\n      <td>9.249166</td>\n      <td>9.365508</td>\n      <td>7.682697</td>\n      <td>8.346578</td>\n      <td>9.030991</td>\n      <td>7.519467</td>\n      <td>8.415932</td>\n      <td>9.235527</td>\n      <td>13.143297</td>\n      <td>13.507578</td>\n      <td>14.704148</td>\n      <td>14.377883</td>\n      <td>13.336893</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "id_vars = ['country_name', 'country_code', 'indicator_name', 'indicator_code']\npop_dataframe = pd.melt(pop_dataframe, \n                        id_vars=id_vars,\n                        value_vars=pop_dataframe.columns[4:].values, \n                        var_name='Year', \n                        value_name='Tax_Rev_Percent_GDP')", "execution_count": 37, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "print(pop_dataframe.shape)\npop_dataframe.head()", "execution_count": 38, "outputs": [{"output_type": "stream", "text": "(15048, 6)\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 38, "data": {"text/plain": "  country_name country_code          indicator_name     indicator_code  Year Tax_Rev_Percent_GDP\n0      Belgium          BEL  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS  1960                None\n1       Belize          BLZ  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS  1960                None\n2        Benin          BEN  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS  1960                None\n3      Bermuda          BMU  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS  1960                None\n4       Bhutan          BTN  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS  1960                None", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country_name</th>\n      <th>country_code</th>\n      <th>indicator_name</th>\n      <th>indicator_code</th>\n      <th>Year</th>\n      <th>Tax_Rev_Percent_GDP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Belgium</td>\n      <td>BEL</td>\n      <td>Tax revenue (% of GDP)</td>\n      <td>GC.TAX.TOTL.GD.ZS</td>\n      <td>1960</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Belize</td>\n      <td>BLZ</td>\n      <td>Tax revenue (% of GDP)</td>\n      <td>GC.TAX.TOTL.GD.ZS</td>\n      <td>1960</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Benin</td>\n      <td>BEN</td>\n      <td>Tax revenue (% of GDP)</td>\n      <td>GC.TAX.TOTL.GD.ZS</td>\n      <td>1960</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bermuda</td>\n      <td>BMU</td>\n      <td>Tax revenue (% of GDP)</td>\n      <td>GC.TAX.TOTL.GD.ZS</td>\n      <td>1960</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bhutan</td>\n      <td>BTN</td>\n      <td>Tax revenue (% of GDP)</td>\n      <td>GC.TAX.TOTL.GD.ZS</td>\n      <td>1960</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "**transform from \"long\" to \"wide\" using pivot_table**"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# convert to numeric (errors='coerce' to convert strings to np.nan)\npop_dataframe['Tax_Rev_Percent_GDP'] = pd.to_numeric(pop_dataframe.Tax_Rev_Percent_GDP, \n                                                                       errors='coerce')\n                     \n# pivot from long to wide\nindex = ['country_name', 'country_code', 'indicator_name', 'indicator_code']\npop_dataframe = pd.pivot_table(pop_dataframe, \n                               values='Tax_Rev_Percent_GDP', \n                               columns=['Year'],\n                               index=index,\n                               aggfunc=np.mean)\n# reset index\npop_dataframe.reset_index(inplace=True)", "execution_count": 39, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "print(pop_dataframe.shape)\npop_dataframe.head()\n# note that columns where all items were NaN were automatically dropped, \n# reducing the number of columns to 49.", "execution_count": 40, "outputs": [{"output_type": "stream", "text": "(264, 49)\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 40, "data": {"text/plain": "Year    country_name country_code          indicator_name     indicator_code  1972  1973  1974  1975  1976  1977  1978  1979  1980  1981  1982  1983  1984  1985  1986  1987  1988  1989  1990  1991  1992  1993       1994       1995       1996       1997       1998       1999       2000       2001       2002       2003       2004      2005       2006       2007       2008       2009       2010       2011       2012       2013       2014       2015  2016\n0        Afghanistan          AFG  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN       NaN   6.883364   5.229756   6.039428   8.434998   9.123651   8.854568   7.471639   7.158330        NaN        NaN   NaN\n1            Albania          ALB  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN        NaN  13.422768   8.553602   9.479293  13.701633        NaN        NaN        NaN  16.160843  16.790842  17.645359       NaN        NaN        NaN        NaN        NaN        NaN  18.022012  17.483234  16.497139  18.313552  18.510208   NaN\n2            Algeria          DZA  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  26.693798  28.599517  30.607004  31.608446  25.026814  27.017746  36.928189  32.045511  31.524905  27.582053  26.803996  30.76547  40.750393  37.431012  45.252935  35.142903  34.402769  37.185853        NaN        NaN        NaN        NaN   NaN\n3     American Samoa          ASM  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN       NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN   NaN\n4            Andorra          AND  Tax revenue (% of GDP)  GC.TAX.TOTL.GD.ZS   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN       NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN   NaN", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Year</th>\n      <th>country_name</th>\n      <th>country_code</th>\n      <th>indicator_name</th>\n      <th>indicator_code</th>\n      <th>1972</th>\n      <th>1973</th>\n      <th>1974</th>\n      <th>1975</th>\n      <th>1976</th>\n      <th>1977</th>\n      <th>1978</th>\n      <th>1979</th>\n      <th>1980</th>\n      <th>1981</th>\n      <th>1982</th>\n      <th>1983</th>\n      <th>1984</th>\n      <th>1985</th>\n      <th>1986</th>\n      <th>1987</th>\n      <th>1988</th>\n      <th>1989</th>\n      <th>1990</th>\n      <th>1991</th>\n      <th>1992</th>\n      <th>1993</th>\n      <th>1994</th>\n      <th>1995</th>\n      <th>1996</th>\n      <th>1997</th>\n      <th>1998</th>\n      <th>1999</th>\n      <th>2000</th>\n      <th>2001</th>\n      <th>2002</th>\n      <th>2003</th>\n      <th>2004</th>\n      <th>2005</th>\n      <th>2006</th>\n      <th>2007</th>\n      <th>2008</th>\n      <th>2009</th>\n      <th>2010</th>\n      <th>2011</th>\n      <th>2012</th>\n      <th>2013</th>\n      <th>2014</th>\n      <th>2015</th>\n      <th>2016</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Afghanistan</td>\n      <td>AFG</td>\n      <td>Tax revenue (% of GDP)</td>\n      <td>GC.TAX.TOTL.GD.ZS</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.883364</td>\n      <td>5.229756</td>\n      <td>6.039428</td>\n      <td>8.434998</td>\n      <td>9.123651</td>\n      <td>8.854568</td>\n      <td>7.471639</td>\n      <td>7.158330</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Albania</td>\n      <td>ALB</td>\n      <td>Tax revenue (% of GDP)</td>\n      <td>GC.TAX.TOTL.GD.ZS</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13.422768</td>\n      <td>8.553602</td>\n      <td>9.479293</td>\n      <td>13.701633</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>16.160843</td>\n      <td>16.790842</td>\n      <td>17.645359</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>18.022012</td>\n      <td>17.483234</td>\n      <td>16.497139</td>\n      <td>18.313552</td>\n      <td>18.510208</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Algeria</td>\n      <td>DZA</td>\n      <td>Tax revenue (% of GDP)</td>\n      <td>GC.TAX.TOTL.GD.ZS</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>26.693798</td>\n      <td>28.599517</td>\n      <td>30.607004</td>\n      <td>31.608446</td>\n      <td>25.026814</td>\n      <td>27.017746</td>\n      <td>36.928189</td>\n      <td>32.045511</td>\n      <td>31.524905</td>\n      <td>27.582053</td>\n      <td>26.803996</td>\n      <td>30.76547</td>\n      <td>40.750393</td>\n      <td>37.431012</td>\n      <td>45.252935</td>\n      <td>35.142903</td>\n      <td>34.402769</td>\n      <td>37.185853</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>American Samoa</td>\n      <td>ASM</td>\n      <td>Tax revenue (% of GDP)</td>\n      <td>GC.TAX.TOTL.GD.ZS</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Andorra</td>\n      <td>AND</td>\n      <td>Tax revenue (% of GDP)</td>\n      <td>GC.TAX.TOTL.GD.ZS</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Thanks for reading this notebook. I hope you enjoyed it!"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": "3.6.4", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "toc": {"threshold": 4, "number_sections": false, "toc_cell": false, "toc_window_display": false, "toc_section_display": "block", "sideBar": true, "navigate_menu": true, "moveMenuLeft": true, "widenNotebook": false, "colors": {"hover_highlight": "#DAA520", "selected_highlight": "#FFD700", "running_highlight": "#FF0000", "wrapper_background": "#FFFFFF", "sidebar_border": "#EEEEEE", "navigate_text": "#333333", "navigate_num": "#000000"}, "nav_menu": {"height": "233px", "width": "252px"}, "toc_position": {"height": "584px", "left": "0px", "right": "895.2px", "top": "109px", "width": "212px"}}, "varInspector": {"window_display": false, "cols": {"lenName": 16, "lenType": 16, "lenVar": 40}, "kernels_config": {"python": {"library": "var_list.py", "delete_cmd_prefix": "del ", "delete_cmd_postfix": "", "varRefreshCmd": "print(var_dic_list())"}, "r": {"library": "var_list.r", "delete_cmd_prefix": "rm(", "delete_cmd_postfix": ") ", "varRefreshCmd": "cat(var_dic_list()) "}}, "types_to_exclude": ["module", "function", "builtin_function_or_method", "instance", "_Feature"], "position": {"height": "710px", "left": "527.96px", "right": "20px", "top": "104.983px", "width": "650px"}}}, "nbformat": 4, "nbformat_minor": 2}